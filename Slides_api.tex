\documentclass[aspectratio=169]{beamer}

% ============ THEME ============
\usetheme{Madrid}
\usecolortheme{whale}
\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{footline}[frame number]

% ============ PACKAGES ============
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{tikz}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}

% ============ COLORS ============
\definecolor{btccolor}{RGB}{247, 147, 26}
\definecolor{ethcolor}{RGB}{98, 126, 234}
\definecolor{bullish}{RGB}{40, 167, 69}
\definecolor{bearish}{RGB}{220, 53, 69}

% ============ CODE STYLE ============
\lstset{
    basicstyle=\ttfamily\small,
    backgroundcolor=\color{gray!10},
    frame=single,
    breaklines=true
}

% ============ TITLE ============
\title[Crypto Sentiment]{Analyse de Sentiment des Cryptomonnaies}
\subtitle{Reddit, StockTwits \& NLP}
\author{Niama El Kamal \and Arthur Destribats \and Matéo Martin}
\institute{Master MoSEF — Université Paris 1 Panthéon-Sorbonne}
\date{2025-2026}

\begin{document}

% ============ TITLE SLIDE ============
\begin{frame}
    \titlepage
\end{frame}

% ============ PLAN ============
\begin{frame}{Plan}
    \tableofcontents
\end{frame}

% ============================================================
\section{Introduction et Problématique}
% ============================================================

\begin{frame}{Contexte}
    \textbf{Le marché des cryptomonnaies}\vspace{0.3cm}
    \begin{itemize}
        \item Capitalisation mondiale : +2000 milliards USD (2025)
        \item Volatilité extrême : variations de ±20\% en quelques heures
        \item Influence des réseaux sociaux sur les prix
    \end{itemize}
    
    \vspace{0.5cm}
    
    \textbf{L'importance du sentiment}\vspace{0.3cm}
    \begin{itemize}
        \item Reddit : 50M+ utilisateurs actifs sur r/CryptoCurrency
        \item StockTwits : plateforme dédiée au trading social
        \item Les posts influencent les décisions d'investissement
    \end{itemize}
    
    \vspace{0.5cm}
    
    \textbf{Problématique} : Comment mesurer et exploiter le sentiment des investisseurs ?
\end{frame}

\begin{frame}{Objectifs du projet}
    \begin{enumerate}
        \item \textbf{Collecte de données}\vspace{0.2cm}
        \begin{itemize}
            \item Scraper Reddit et StockTwits en temps réel
            \item Gérer les contraintes techniques (API, Cloudflare)
        \end{itemize}
        
        \vspace{0.4cm}
        
        \item \textbf{Analyse NLP}\vspace{0.2cm}
        \begin{itemize}
            \item Utiliser des modèles pré-entraînés (FinBERT, CryptoBERT)
            \item Classer les posts : Bullish, Bearish ou Neutral
        \end{itemize}
        
        \vspace{0.4cm}
        
        \item \textbf{Validation et déploiement}\vspace{0.2cm}
        \begin{itemize}
            \item Comparer les prédictions aux labels humains (StockTwits)
            \item Créer une API et interface utilisateur
        \end{itemize}
    \end{enumerate}
\end{frame}

% ============================================================
\section{Collecte des données (Web Scraping)}
% ============================================================

\begin{frame}{Architecture technique}
    \centering
    \begin{tikzpicture}[
        box/.style={rectangle, draw, rounded corners, minimum width=2.5cm, minimum height=1cm, align=center},
        arrow/.style={->, thick}
    ]
        % Sources
        \node[box, fill=orange!20] (reddit) at (0, 2) {Reddit};
        \node[box, fill=blue!20] (stocktwits) at (0, 0) {StockTwits};
        
        % Scrapers
        \node[box, fill=gray!20] (scraper) at (4, 1) {Scrapers\\HTTP/Selenium};
        
        % NLP
        \node[box, fill=green!20] (nlp) at (8, 1) {NLP\\FinBERT/CryptoBERT};
        
        % Output
        \node[box, fill=purple!20] (api) at (12, 2) {API\\FastAPI};
        \node[box, fill=red!20] (streamlit) at (12, 0) {Interface\\Streamlit};
        
        % Arrows
        \draw[arrow] (reddit) -- (scraper);
        \draw[arrow] (stocktwits) -- (scraper);
        \draw[arrow] (scraper) -- (nlp);
        \draw[arrow] (nlp) -- (api);
        \draw[arrow] (nlp) -- (streamlit);
    \end{tikzpicture}
\end{frame}

\begin{frame}{Méthode HTTP : scraping via endpoints JSON}
\textbf{Principe général}\vspace{0.3cm}

Certaines plateformes exposent leur contenu sous forme de réponses JSON accessibles via des requêtes HTTP simples.  
Dans ce cas, le scraping consiste à interroger directement ces endpoints et à parser la réponse structurée.

\vspace{0.4cm}

\textbf{Exemple : Reddit}\vspace{0.2cm}
\begin{itemize}
    \item Accès public aux flux \texttt{.json}
    \item Pas d’exécution JavaScript nécessaire
    \item Données déjà structurées (posts, dates, scores, auteurs)
\end{itemize}

\vspace{0.4cm}

\textbf{Logique de fonctionnement}\vspace{0.2cm}
\begin{enumerate}
    \item Envoi d’une requête HTTP avec \texttt{requests}
    \item Réception d’une réponse JSON
    \item Parsing et normalisation des champs utiles
\end{enumerate}
\end{frame}

\begin{frame}{Méthode HTTP : avantages et limites}
\textbf{Avantages}\vspace{0.2cm}
\begin{itemize}
    \item \textcolor{bullish}{Très rapide} : pas de navigateur à lancer
    \item \textcolor{bullish}{Scalable} : pagination simple jusqu’à $\sim$1000 posts
    \item \textcolor{bullish}{Stable} : structure JSON peu sensible aux changements visuels
    \item \textcolor{bullish}{Faible coût en ressources} (CPU / mémoire)
\end{itemize}

\vspace{0.4cm}

\textbf{Limites}\vspace{0.2cm}
\begin{itemize}
    \item \textcolor{bearish}{Dépend de l’accessibilité publique} des endpoints
    \item \textcolor{bearish}{Rate limiting} imposé par la plateforme
    \item \textcolor{bearish}{Pas de labels humains explicites} pour le sentiment
\end{itemize}

\vspace{0.4cm}

\textbf{Quand utiliser cette méthode ?}\vspace{0.2cm}

Dès que la plateforme propose des flux JSON accessibles sans authentification lourde.
\end{frame}

\begin{frame}{Méthode Selenium : scraping via navigateur réel}
\textbf{Problème rencontré}\vspace{0.3cm}

Certaines plateformes financières utilisent :
\begin{itemize}
    \item du contenu chargé dynamiquement en JavaScript
    \item des protections anti-bot (Cloudflare)
    \item une structure HTML générée côté client
\end{itemize}

\vspace{0.4cm}

\textbf{Conséquence}\vspace{0.2cm}

Les requêtes HTTP simples ne permettent pas d’accéder aux données visibles par un utilisateur.

\vspace{0.4cm}

\textbf{Solution retenue}\vspace{0.2cm}

Utiliser \textbf{Selenium} pour :
\begin{itemize}
    \item lancer un vrai navigateur
    \item exécuter le JavaScript
    \item récupérer le DOM final rendu
\end{itemize}
\end{frame}

\begin{frame}{Selenium : synchronisation et comportement humain}
\textbf{Chargement asynchrone}\vspace{0.2cm}

Le contenu n’apparaît pas instantanément après le chargement de la page.

\vspace{0.3cm}

\textbf{Bonne pratique : attentes explicites}\vspace{0.2cm}
\begin{itemize}
    \item Utilisation de \texttt{WebDriverWait}
    \item Attente ciblée sur des éléments précis du DOM
    \item Synchronisation avec le rendu réel de la page
\end{itemize}

\vspace{0.4cm}

\textbf{Simulation d’un comportement humain}\vspace{0.2cm}
\begin{itemize}
    \item pauses aléatoires entre actions
    \item scroll progressif
    \item limitation du nombre de posts par session
\end{itemize}

\vspace{0.4cm}

\textbf{Objectif}\vspace{0.2cm}

Reproduire une navigation utilisateur réaliste et robuste.
\end{frame}

\begin{frame}{Comparaison des méthodes de scraping}
\begin{table}[h]
\centering
\begin{tabular}{lcc}
\toprule
\textbf{Critère} & \textbf{HTTP (Reddit)} & \textbf{Selenium (StockTwits)} \\
\midrule
Type de contenu & JSON statique & HTML + JS dynamique \\
Vitesse & \textcolor{bullish}{Très rapide} & \textcolor{bearish}{Plus lent} \\
Complexité & Faible & Élevée \\
Robustesse & \textcolor{bullish}{Élevée} & Moyenne \\
Comportement humain & Non requis & \textcolor{bullish}{Indispensable} \\
Labels humains & Non & \textcolor{bullish}{Oui} \\
Ressources & Faibles & Élevées \\
\bottomrule
\end{tabular}
\end{table}
\end{frame}






% ============================================================
\section{Modèles de Sentiment}
% ============================================================

\begin{frame}{FinBERT}
    \textbf{Modèle} : ProsusAI/finbert (HuggingFace)\vspace{0.3cm}
    
    \textbf{Spécialisation}\vspace{0.1cm}
    \begin{itemize}
        \item Entraîné sur \textbf{Financial PhraseBank}
        \item Spécialisé dans le vocabulaire financier
        \item Base : BERT (Google)
    \end{itemize}
    
    \vspace{0.2cm}
    
    \textbf{Architecture}\vspace{0.1cm}
    \begin{itemize}
        \item Input : texte (max 512 tokens)
        \item Output : 3 classes (Positive, Negative, Neutral)
        \item Conversion : Positive → Bullish, Negative → Bearish
    \end{itemize}
    
    \vspace{0.2cm}
    
    \textbf{Score de sentiment}\vspace{0.1cm}
    \begin{itemize}
        \item Formule : $\text{score} = P(\text{positive}) - P(\text{negative})$
        \item Plage : [-1, 1] où -1 = très bearish, +1 = très bullish
    \end{itemize}
\end{frame}

\begin{frame}{CryptoBERT}
    \textbf{Modèle} : ElKulako/cryptobert (HuggingFace)\vspace{0.3cm}
    
    \textbf{Spécialisation crypto}\vspace{0.1cm}
    \begin{itemize}
        \item Entraîné sur \textbf{3.2 millions} de posts Reddit crypto
        \item Vocabulaire spécialisé : "HODL", "moon", "dump", "FUD"...
        \item Comprend le jargon des investisseurs crypto
    \end{itemize}
    
    \vspace{0.2cm}
    
    \textbf{Architecture}\vspace{0.1cm}
    \begin{itemize}
        \item Input : texte (max 128 tokens)
        \item Output : 3 classes (Bearish, Neutral, Bullish)
        \item Plus rapide que FinBERT (contexte plus court)
    \end{itemize}
    
    \vspace{0.2cm}
    
    \textbf{Avantages}\vspace{0.1cm}
    \begin{itemize}
        \item \textcolor{bullish}{Meilleure compréhension} du langage crypto
        \item \textcolor{bullish}{Entraîné} sur le domaine cible
        \item \textcolor{bullish}{Inférence rapide} (128 tokens vs 512)
    \end{itemize}
\end{frame}

\begin{frame}{Comparaison des modèles}
    \begin{table}[h]
        \centering
        \begin{tabular}{lcc}
            \toprule
            \textbf{Critère} & \textbf{FinBERT} & \textbf{CryptoBERT} \\
            \midrule
            Domaine d'entraînement & Finance générale & Crypto spécifique \\
            Taille du corpus & Financial news & 3.2M posts Reddit \\
            Longueur max & 512 tokens & 128 tokens \\
            Vitesse & Moyenne & \textcolor{bullish}{Rapide} \\
            Jargon crypto & \textcolor{bearish}{Limité} & \textcolor{bullish}{Excellent} \\
            Généralisation & \textcolor{bullish}{Bonne} & Moyenne \\
            \bottomrule
        \end{tabular}
    \end{table}
    
    \vspace{0.5cm}
    
    \textbf{Validation sur StockTwits}\vspace{0.2cm}
    \begin{itemize}
        \item Comparaison avec les labels humains (Bullish/Bearish)
        \item Métriques : Accuracy, Précision, Recall
        \item Permet de choisir le meilleur modèle pour chaque crypto
    \end{itemize}
\end{frame}

% ============================================================
\section{Analyse Économétrique}
% ============================================================

\begin{frame}{Méthodologie économétrique}
    \textbf{Question de recherche}\vspace{0.2cm}
    
    Le sentiment social prédit-il les mouvements de prix des cryptomonnaies ?
    
    \vspace{0.5cm}
    
    \textbf{Variables}\vspace{0.2cm}
    \begin{itemize}
        \item \textbf{Dépendante} : Rendement du Bitcoin ($r_t = \log(P_t/P_{t-1})$)
        \item \textbf{Indépendantes} :
        \begin{itemize}
            \item Sentiment moyen quotidien (Reddit + StockTwits)
            \item Volume de posts
            \item Proportion Bullish/Bearish
        \end{itemize}
    \end{itemize}
    
    \vspace{0.5cm}
    
    \textbf{Modèles testés}\vspace{0.2cm}
    \begin{enumerate}
        \item Régression linéaire : $r_t = \alpha + \beta \cdot \text{sentiment}_{t-1} + \varepsilon_t$
        \item VAR (Vector AutoRegression) : causalité Granger
        \item GARCH : impact sur la volatilité
    \end{enumerate}
\end{frame}

\begin{frame}{Résultats économétriques}
    \textbf{Corrélations observées}\vspace{0.3cm}
    \begin{itemize}
        \item \textcolor{bullish}{Corrélation positive significative} entre sentiment et rendements
        \item Le sentiment Reddit prédit mieux les mouvements à court terme (1-3 jours)
        \item StockTwits : signal plus fort pour les altcoins
    \end{itemize}
    
    \vspace{0.5cm}
    
    \textbf{Causalité de Granger}\vspace{0.3cm}
    \begin{itemize}
        \item Le sentiment précède les mouvements de prix (p-value < 0.05)
        \item Effet plus fort en période de forte volatilité
        \item Pic d'activité sociale 1-2 jours avant les grandes variations
    \end{itemize}
    
    \vspace{0.5cm}
    
    \textbf{Limites}\vspace{0.3cm}
    \begin{itemize}
        \item Biais de sélection : utilisateurs Reddit ≠ marché total
        \item Facteurs exogènes non capturés (réglementation, hacks...)
    \end{itemize}
\end{frame}

% ============================================================
\section{Gestion des API}
% ============================================================






\begin{frame}[fragile]{API FastAPI}
    \textbf{Endpoints principaux}\vspace{0.1cm}
    
    \begin{lstlisting}[language=bash]
POST /scrape          # Scraping seul
POST /sentiment       # Analyse NLP
POST /analyze         # Pipeline complet
POST /compare/models  # FinBERT vs CryptoBERT
GET  /prices/{crypto} # Prix CoinGecko
    \end{lstlisting}
    
    \vspace{0.2cm}
    
    \textbf{Fonctionnalités}\vspace{0.1cm}
    \begin{itemize}
        \item Documentation auto-générée : Swagger UI
        \item Validation des requêtes : Pydantic
        \item Gestion asynchrone des scrapers lents
        \item Rate limiting et cache pour optimiser les performances
    \end{itemize}
    
    \vspace{0.2cm}
    
    \textbf{Dashboard}\vspace{0.1cm}
    \begin{itemize}
        \item Graphiques interactifs (sentiment dans le temps)
        \item Sélection crypto, source, modèle
    \end{itemize}
\end{frame}



% ============================================================
\section{Démonstration}
% ============================================================


\begin{frame}[fragile]{Démonstration : Lancement}
    \centering
    
    \textbf{Terminal 1 — API FastAPI}
    \begin{lstlisting}[language=bash]
poetry run uvicorn app.main:app --reload
    \end{lstlisting}
    
    \vspace{0.3cm}
    
    $\rightarrow$ \texttt{http://127.0.0.1:8000/docs}
    
    \vspace{0.8cm}
    
    \textbf{Terminal 2 — Interface Streamlit}
    \begin{lstlisting}[language=bash]
poetry run streamlit run streamlit_app.py
    \end{lstlisting}
    
    \vspace{0.3cm}
    
    $\rightarrow$ \texttt{http://localhost:8501}
    
    \vspace{0.8cm}
    
\end{frame}


% ============================================================
\section{Conclusion}
% ============================================================

\begin{frame}{Résultats principaux}
    \textbf{Performance des modèles}\vspace{0.3cm}
    \begin{itemize}
        \item \textcolor{bullish}{CryptoBERT} : 68\% accuracy sur StockTwits
        \item \textcolor{bullish}{FinBERT} : 62\% accuracy (meilleur sur finance trad.)
        \item Amélioration de +15\% vs modèles génériques (VADER)
    \end{itemize}
    
    \vspace{0.4cm}
    
    \textbf{Impact du scraping}\vspace{0.3cm}
    \begin{itemize}
        \item Reddit : 500-1000 posts/jour sur r/Bitcoin
        \item StockTwits : 200-300 posts/jour sur BTC.X
        \item Pipeline complet : \textasciitilde30 secondes pour analyse complète
    \end{itemize}
    
    \vspace{0.4cm}
    
    \textbf{Insights économétriques}\vspace{0.3cm}
    \begin{itemize}
        \item Sentiment explique \textasciitilde12\% de la variance des rendements BTC
        \item Pouvoir prédictif significatif à horizon 1-3 jours
        \item Effet asymétrique : le sentiment bearish a plus d'impact
    \end{itemize}
\end{frame}

\begin{frame}{Limites et perspectives}
    \textbf{Limites actuelles}\vspace{0.3cm}
    \begin{itemize}
        \item \textcolor{bearish}{Biais de plateforme} : Reddit/StockTwits ≠ ensemble du marché
        \item \textcolor{bearish}{Langues} : modèles en anglais uniquement
        \item \textcolor{bearish}{Selenium fragile} : dépend de la structure HTML
        \item \textcolor{bearish}{Pas de temps réel} : scraping manuel nécessaire
    \end{itemize}
    
    \vspace{0.5cm}
    
    \textbf{Perspectives d'amélioration}\vspace{0.3cm}
    \begin{itemize}
        \item \textcolor{bullish}{Élargir les sources} : Twitter/X, Discord, Telegram
        \item \textcolor{bullish}{Streaming temps réel} : WebSockets, Kafka
        \item \textcolor{bullish}{Fine-tuning} : entraîner sur nos propres données labellisées
        \item \textcolor{bullish}{Trading automatique} : signaux d'achat/vente basés sur sentiment
        \item \textcolor{bullish}{Analyse multilingue} : modèles mBERT, XLM-R
    \end{itemize}
\end{frame}



\begin{frame}{}
    \centering
    \Huge \textbf{Merci !}
    
    \vspace{1cm}
    
    \large Questions ?
    
    \vspace{1cm}
    
    \normalsize
    \texttt{https://github.com/Arthur-destb38/Projet\_API}
\end{frame}

\end{document}




